#!/usr/bin/env python3
import os
import re
import json
import hashlib
from pathlib import Path

# è¨­å®šè·¯å¾‘
BASE_DIR = Path("client/src")
PAGES_DIR = BASE_DIR / "pages"
LOCALE_PATH = BASE_DIR / "i18n/locales/zh-TW.json"
EN_LOCALE_PATH = BASE_DIR / "i18n/locales/en.json"

# æ’é™¤åå–® (ä¿è­·è³‡æ–™çµæ§‹èˆ‡ç‰¹å®šèªæ³•)
EXCLUDE_PATTERNS = [
    r"const\s+\w+\s*=",
    r"console\.",
    r"^\s*//",
    r"return\s*;",
    r"path:",
    r"icon:",
    r"label:",  # æ’é™¤è·¯ç”±èˆ‡åœ–ç¤ºå®šç¾©
    r"address\s*:",
    r"phone\s*:",  # ä¿è­·åœ°å€è³‡æ–™
]

# è¼‰å…¥ç¾æœ‰ç¿»è­¯
def load_json(path):
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

zh_data = load_json(LOCALE_PATH)
en_data = load_json(EN_LOCALE_PATH)

def get_page_key(filename):
    # AdminSubscribers.tsx -> adminSubscribers
    name = filename.replace(".tsx", "")
    return name[0].lower() + name[1:]

def generate_hash_key(text):
    # ç”ŸæˆçŸ­ Hash
    return "t_" + hashlib.md5(text.encode("utf-8")).hexdigest()[:8]

def process_file(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    page_key = get_page_key(file_path.name)
    modified = False
    
    # ç¢ºä¿ page key å­˜åœ¨æ–¼å­—å…¸
    if page_key not in zh_data:
        zh_data[page_key] = {}
        en_data[page_key] = {}
    
    # 1. æ³¨å…¥ Hook (å¦‚æœé‚„æ²’æœ‰)
    if "useTranslation" not in content:
        # æ·»åŠ  import
        if 'import { useTranslation }' not in content:
            last_import = content.rfind("import ")
            end_of_import = content.find("\n", last_import) + 1
            content = content[:end_of_import] + 'import { useTranslation } from "react-i18next";\nimport SEOHead from "@/components/seo/SEOHead";\n' + content[end_of_import:]
        
        # æ·»åŠ  hook
        export_match = re.search(r"export default function \w+\(\) \{", content)
        if export_match:
            idx = export_match.end()
            content = content[:idx] + '\n  const { t } = useTranslation();' + content[idx:]
            modified = True
    
    # 2. æ³¨å…¥ SEOHead (å¦‚æœé‚„æ²’æœ‰)
    if "<SEOHead" not in content:
        return_match = re.search(r"return \(\s*<div", content)  # å‡è¨­å¤§å¤šæ•¸é é¢ä»¥ <div é–‹é ­
        if not return_match:
            return_match = re.search(r"return \(\s*<>", content)
            
        if return_match:
            idx = return_match.end()
            content = content[:idx] + f'\n      <SEOHead pageKey="{page_key}" />' + content[idx:]
            modified = True
    
    # 3. æ›¿æ› JSX æ–‡å­— >ä¸­æ–‡<
    # é‚è¼¯ï¼šå°‹æ‰¾ > ä¹‹å¾Œã€< ä¹‹å‰çš„ä¸­æ–‡
    def replace_jsx_text(match):
        prefix = match.group(1)  # >
        text = match.group(2)   # ä¸­æ–‡å…§å®¹
        suffix = match.group(3)  # <
        
        if not re.search(r"[\u4e00-\u9fff]", text):
            return match.group(0)
        if any(re.search(p, text) for p in EXCLUDE_PATTERNS):
            return match.group(0)
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ (é¿å…é‡è¤‡ç”Ÿæˆ)
        key = generate_hash_key(text)
        full_key = f"{page_key}.{key}"
        
        # å¯«å…¥å­—å…¸
        zh_data[page_key][key] = text.strip()
        if key not in en_data[page_key]:  # è‹±æ–‡æš«æ™‚ç”¨ä¸­æ–‡ä½”ä½ï¼Œæ¨™è¨˜ TODO
            en_data[page_key][key] = f"[EN] {text.strip()}"
            
        return f"{prefix}{{t('{full_key}')}}{suffix}"
    
    content = re.sub(r"(>)([^<>{}]+?[\u4e00-\u9fff]+[^<>{}]*?)(<)", replace_jsx_text, content)
    
    # 4. æ›¿æ›å±¬æ€§æ–‡å­— placeholder="ä¸­æ–‡"
    def replace_attr(match):
        attr = match.group(1)
        text = match.group(2)
        
        if not re.search(r"[\u4e00-\u9fff]", text):
            return match.group(0)
        
        key = generate_hash_key(text)
        full_key = f"{page_key}.{key}"
        
        zh_data[page_key][key] = text.strip()
        if key not in en_data[page_key]:
            en_data[page_key][key] = f"[EN] {text.strip()}"
            
        return f"{attr}={{t('{full_key}')}}"
    
    content = re.sub(r'([a-zA-Z-]+)="([^"]*?[\u4e00-\u9fff]+[^"]*?)"', replace_attr, content)
    
    # å¯«å›æª”æ¡ˆ
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)
    
    print(f"âœ… Processed: {file_path.name}")

# åŸ·è¡Œéæ­·
print("ğŸš€ Starting Universal Fixer...")
for root, dirs, files in os.walk(PAGES_DIR):
    for file in files:
        if file.endswith(".tsx"):
            process_file(Path(root) / file)

# å¯«å›å­—å…¸
with open(LOCALE_PATH, "w", encoding="utf-8") as f:
    json.dump(zh_data, f, ensure_ascii=False, indent=2)
with open(EN_LOCALE_PATH, "w", encoding="utf-8") as f:
    json.dump(en_data, f, ensure_ascii=False, indent=2)

print("ğŸ’¾ Dictionaries Updated!")
print(f"ğŸ“Š Total pages processed: {len(zh_data)}")
print(f"ğŸ“Š Total translation keys: {sum(len(v) if isinstance(v, dict) else 0 for v in zh_data.values())}")
