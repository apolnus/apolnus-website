#!/usr/bin/env python3
"""
å‡ç´šç‰ˆ Python è…³æœ¬ï¼šå®ŒæˆçœŸæ­£çš„æ–‡å­—æ›¿æ›å·¥ä½œ
ä½¿ç”¨ AST/Regex é›™é‡ç­–ç•¥ï¼Œè‡ªå‹•ç”Ÿæˆ Keysï¼Œä¿è­·è³‡æ–™å€å¡Š
"""

import re
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple

# ç›®æ¨™é é¢åˆ—è¡¨
TARGET_PAGES = [
    'WhereToBuy',
    'ServiceCenters',
    'About',
    'FAQ',
    'Profile',
    'WarrantyRegistration',
    'SupportTicket',
    'Tickets',
    'Support',
    'PartnerProgram',
    'Careers',
    'Privacy',
    'Terms',
    'NotFound',
]

# é é¢è·¯å¾‘
PAGES_DIR = Path('/home/ubuntu/apolnus/client/src/pages')
TRANSLATIONS_DIR = Path('/home/ubuntu/apolnus/client/src/i18n/locales')

# è¼‰å…¥ç¾æœ‰ç¿»è­¯
with open(TRANSLATIONS_DIR / 'zh-TW.json', 'r', encoding='utf-8') as f:
    existing_translations_zh = json.load(f)

with open(TRANSLATIONS_DIR / 'en.json', 'r', encoding='utf-8') as f:
    existing_translations_en = json.load(f)

# é é¢é…ç½®
PAGE_CONFIG = {
    'WhereToBuy': 'whereToBuy',
    'ServiceCenters': 'serviceCenters',
    'About': 'about',
    'FAQ': 'faq',
    'Profile': 'profile',
    'WarrantyRegistration': 'warrantyRegistration',
    'SupportTicket': 'supportTicket',
    'Tickets': 'tickets',
    'Support': 'support',
    'PartnerProgram': 'partnerProgram',
    'Careers': 'careers',
    'Privacy': 'privacy',
    'Terms': 'terms',
    'NotFound': 'notFound',
}

# æ’é™¤åå–®ï¼ˆè³‡æ–™å€å¡Šä¿è­·ï¼‰
EXCLUDE_PATTERNS = [
    r'const\s+stores\s*=',
    r'const\s+dealers\s*=',
    r'const\s+onlinePlatforms\s*=',
    r'const\s+platforms\s*=',
    r'const\s+serviceCenters\s*=',
    r'address\s*:',
    r'phone\s*:',
    r'email\s*:',
    r'url\s*:',
    r'href\s*=',
    r'src\s*=',
]

# éœ€è¦æ›¿æ›çš„å±¬æ€§
TRANSLATABLE_ATTRS = ['placeholder', 'alt', 'title', 'aria-label']

def is_in_exclude_block(line: str, context_lines: List[str], line_idx: int) -> bool:
    """åˆ¤æ–·ç•¶å‰è¡Œæ˜¯å¦åœ¨æ’é™¤å€å¡Šå…§"""
    # æª¢æŸ¥ç•¶å‰è¡Œ
    for pattern in EXCLUDE_PATTERNS:
        if re.search(pattern, line):
            return True
    
    # æª¢æŸ¥ä¸Šä¸‹æ–‡ï¼ˆå‰å¾Œ 5 è¡Œï¼‰
    start = max(0, line_idx - 5)
    end = min(len(context_lines), line_idx + 5)
    context = '\n'.join(context_lines[start:end])
    
    # æª¢æŸ¥æ˜¯å¦åœ¨è³‡æ–™é™£åˆ—å…§
    if re.search(r'const\s+\w+\s*=\s*\[', context):
        # æª¢æŸ¥æ˜¯å¦åœ¨é™£åˆ—çµæŸä¹‹å‰
        bracket_count = context[:context.find(line) if line in context else 0].count('[') - context[:context.find(line) if line in context else 0].count(']')
        if bracket_count > 0:
            return True
    
    return False

def contains_chinese(text: str) -> bool:
    """æª¢æŸ¥æ–‡å­—æ˜¯å¦åŒ…å«ä¸­æ–‡"""
    return bool(re.search(r'[\u4e00-\u9fff]', text))

def should_translate(text: str, context: str = '') -> bool:
    """åˆ¤æ–·æ–‡å­—æ˜¯å¦éœ€è¦ç¿»è­¯"""
    # è·³éç©ºç™½
    if not text or not text.strip():
        return False
    
    # åªç¿»è­¯åŒ…å«ä¸­æ–‡çš„æ–‡å­—
    if not contains_chinese(text):
        return False
    
    # è·³é URL
    if text.startswith('http'):
        return False
    
    # è·³éè·¯å¾‘
    if '/' in text and not ' ' in text:
        return False
    
    # è·³é className
    if 'className' in context:
        return False
    
    # è·³é Tailwind classes
    if any(x in text for x in ['px-', 'py-', 'bg-', 'text-', 'border-', 'rounded-', 'flex', 'grid']):
        return False
    
    # è·³éé›»è©±è™Ÿç¢¼
    if re.match(r'^[\d\-\(\)\s]+$', text):
        return False
    
    # è·³éå–®å­—ç¬¦
    if len(text.strip()) <= 1:
        return False
    
    return True

def generate_key_from_text(text: str, page_key: str) -> str:
    """å¾æ–‡å­—ç”Ÿæˆç¿»è­¯ key"""
    # æŸ¥æ‰¾ç¾æœ‰ç¿»è­¯ä¸­æ˜¯å¦å·²ç¶“æœ‰é€™å€‹æ–‡å­—
    def find_existing_key(translations: dict, target_text: str, prefix: str = '') -> str:
        for key, value in translations.items():
            full_key = f'{prefix}.{key}' if prefix else key
            if isinstance(value, dict):
                result = find_existing_key(value, target_text, full_key)
                if result:
                    return result
            elif isinstance(value, str) and value.strip() == target_text.strip():
                return full_key
        return ''
    
    # å…ˆå˜—è©¦åœ¨ç¾æœ‰ç¿»è­¯ä¸­æŸ¥æ‰¾
    existing_key = find_existing_key(existing_translations_zh, text, page_key)
    if existing_key:
        return existing_key
    
    # ç”Ÿæˆæ–° key
    # ç°¡åŒ–æ–‡å­—
    simplified = text[:30].strip()
    # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
    simplified = re.sub(r'[^\w\s]', '', simplified)
    # è½‰æ›ç‚ºæ‹¼éŸ³æˆ–ä½¿ç”¨ç°¡åŒ–é‚è¼¯
    words = simplified.split()
    if words:
        # ä½¿ç”¨å‰å¹¾å€‹å­—ä½œç‚º key
        key = '_'.join(words[:3]).lower()
        # ç§»é™¤é ASCII å­—ç¬¦
        key = re.sub(r'[^\x00-\x7F]+', '', key)
        if not key:
            # å¦‚æœæ²’æœ‰è‹±æ–‡ï¼Œä½¿ç”¨ hash
            key = f'text_{hash(text) % 10000}'
    else:
        key = f'text_{hash(text) % 10000}'
    
    return f'{page_key}.{key}'

def replace_jsx_text(content: str, page_key: str) -> Tuple[str, Dict[str, str]]:
    """æ›¿æ› JSX æ–‡å­—"""
    lines = content.split('\n')
    new_lines = []
    new_translations = {}
    
    in_exclude_block = False
    bracket_depth = 0
    
    for i, line in enumerate(lines):
        # æª¢æŸ¥æ˜¯å¦åœ¨æ’é™¤å€å¡Š
        if is_in_exclude_block(line, lines, i):
            new_lines.append(line)
            in_exclude_block = True
            continue
        
        # è¿½è¹¤å¤§æ‹¬è™Ÿæ·±åº¦
        bracket_depth += line.count('{') - line.count('}')
        
        # å¦‚æœåœ¨è³‡æ–™å€å¡Šå…§ï¼Œè·³é
        if in_exclude_block and bracket_depth > 0:
            new_lines.append(line)
            continue
        else:
            in_exclude_block = False
        
        # æ›¿æ› JSX æ¨™ç±¤å…§çš„ç´”æ–‡å­—
        # ä¾‹å¦‚ï¼š<h1>è³¼è²·é€šè·¯</h1> -> <h1>{t('whereToBuy.title')}</h1>
        def replace_tag_text(match):
            opening_tag = match.group(1)
            text = match.group(2)
            closing_tag = match.group(3)
            
            if should_translate(text, line):
                key = generate_key_from_text(text, page_key)
                new_translations[key] = text
                return f'{opening_tag}{{t(\'{key}\')}}{closing_tag}'
            return match.group(0)
        
        # åŒ¹é… <tag>text</tag> æ ¼å¼
        line = re.sub(
            r'(<[a-zA-Z][^>]*>)([^<{]+)(</[a-zA-Z][^>]*>)',
            replace_tag_text,
            line
        )
        
        # æ›¿æ›å±¬æ€§å…§çš„æ–‡å­—
        # ä¾‹å¦‚ï¼šplaceholder="æœå°‹..." -> placeholder={t('whereToBuy.searchPlaceholder')}
        for attr in TRANSLATABLE_ATTRS:
            def replace_attr_text(match):
                attr_name = match.group(1)
                text = match.group(2)
                
                if should_translate(text, line):
                    key = generate_key_from_text(text, page_key)
                    new_translations[key] = text
                    return f'{attr_name}={{t(\'{key}\')}}'
                return match.group(0)
            
            line = re.sub(
                rf'({attr})\s*=\s*["\']([^"\']+)["\']',
                replace_attr_text,
                line
            )
        
        new_lines.append(line)
    
    return '\n'.join(new_lines), new_translations

def process_page(page_name: str) -> bool:
    """è™•ç†å–®å€‹é é¢"""
    page_file = PAGES_DIR / f'{page_name}.tsx'
    
    if not page_file.exists():
        print(f'âš ï¸  é é¢ä¸å­˜åœ¨: {page_name}')
        return False
    
    print(f'\nğŸ“„ è™•ç†é é¢: {page_name}')
    
    # è®€å–æª”æ¡ˆ
    with open(page_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç²å–é é¢ key
    page_key = PAGE_CONFIG.get(page_name, page_name.lower())
    
    # æ›¿æ›æ–‡å­—
    new_content, new_translations = replace_jsx_text(content, page_key)
    
    if new_translations:
        print(f'   âœ… æ‰¾åˆ° {len(new_translations)} å€‹éœ€è¦ç¿»è­¯çš„æ–‡å­—')
        
        # ä¿å­˜ä¿®æ”¹å¾Œçš„æª”æ¡ˆ
        with open(page_file, 'w', encoding='utf-8') as f:
            f.write(new_content)
        print(f'   âœ… æ–‡å­—æ›¿æ›å®Œæˆ')
        
        # æ›´æ–°ç¿»è­¯æª”æ¡ˆ
        # TODO: é€™è£¡éœ€è¦å°‡ new_translations åˆä½µåˆ°ç¾æœ‰ç¿»è­¯ä¸­
        print(f'   â„¹ï¸  æ–°ç¿»è­¯: {list(new_translations.keys())[:5]}...')
    else:
        print(f'   â„¹ï¸  æ²’æœ‰æ‰¾åˆ°éœ€è¦æ›¿æ›çš„æ–‡å­—')
    
    return True

def main():
    """ä¸»å‡½æ•¸"""
    print('ğŸš€ é–‹å§‹æ–‡å­—æ›¿æ›æ‰¹æ¬¡è™•ç†...\n')
    print('=' * 60)
    
    success_count = 0
    failed_count = 0
    
    for page_name in TARGET_PAGES[:3]:  # å…ˆè™•ç†å‰ 3 å€‹é é¢ä½œç‚ºæ¸¬è©¦
        try:
            if process_page(page_name):
                success_count += 1
            else:
                failed_count += 1
        except Exception as e:
            print(f'âŒ è™•ç† {page_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
            import traceback
            traceback.print_exc()
            failed_count += 1
    
    print('\n' + '=' * 60)
    print(f'\nâœ… æ–‡å­—æ›¿æ›å®Œæˆï¼')
    print(f'ğŸ“Š æˆåŠŸ: {success_count} å€‹é é¢')
    print(f'ğŸ“Š å¤±æ•—: {failed_count} å€‹é é¢')

if __name__ == '__main__':
    main()
