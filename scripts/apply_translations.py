#!/usr/bin/env python3
"""
è‡ªå‹•åŒ–æ‰¹æ¬¡è™•ç†è…³æœ¬ï¼šæ•´åˆæ‰€æœ‰é é¢çš„ç¿»è­¯å’Œ SEO
éµå®ˆã€ŒUI ç¿»è­¯ï¼Œè³‡æ–™ä¿ç•™ã€åŸå‰‡
"""

import re
import os
from pathlib import Path

# ç›®æ¨™é é¢åˆ—è¡¨
TARGET_PAGES = [
    'WhereToBuy',
    'ServiceCenters',
    'About',
    'FAQ',
    'Profile',
    'WarrantyRegistration',
    'SupportTicket',
    'Tickets',
    'Support',
    'PartnerProgram',
    'Careers',
    'Privacy',
    'Terms',
    'NotFound',
]

# é é¢è·¯å¾‘
PAGES_DIR = Path('/home/ubuntu/apolnus/client/src/pages')

# é é¢å°æ‡‰çš„ç¿»è­¯ key å’Œ SEO key
PAGE_CONFIG = {
    'WhereToBuy': {'key': 'whereToBuy', 'seo': 'whereToBuy'},
    'ServiceCenters': {'key': 'serviceCenters', 'seo': 'serviceCenters'},
    'About': {'key': 'about', 'seo': 'about'},
    'FAQ': {'key': 'faq', 'seo': 'faq'},
    'Profile': {'key': 'profile', 'seo': 'profile'},
    'WarrantyRegistration': {'key': 'warrantyRegistration', 'seo': 'warrantyRegistration'},
    'SupportTicket': {'key': 'supportTicket', 'seo': 'supportTicket'},
    'Tickets': {'key': 'tickets', 'seo': 'tickets'},
    'Support': {'key': 'support', 'seo': 'support'},
    'PartnerProgram': {'key': 'partnerProgram', 'seo': 'partnerProgram'},
    'Careers': {'key': 'careers', 'seo': 'careers'},
    'Privacy': {'key': 'privacy', 'seo': 'privacy'},
    'Terms': {'key': 'terms', 'seo': 'terms'},
    'NotFound': {'key': 'notFound', 'seo': 'notFound'},
}

def has_translation_hook(content):
    """æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰ useTranslation hook"""
    return 'useTranslation' in content and 'const { t }' in content

def has_seo_component(content):
    """æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰ SEOHead çµ„ä»¶"""
    return 'SEOHead' in content

def add_imports(content, page_name):
    """æ·»åŠ å¿…è¦çš„ imports"""
    lines = content.split('\n')
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ  useTranslation
    needs_translation = not has_translation_hook(content)
    needs_seo = not has_seo_component(content)
    
    if not needs_translation and not needs_seo:
        return content
    
    # æ‰¾åˆ°æœ€å¾Œä¸€å€‹ import èªå¥çš„ä½ç½®
    last_import_idx = 0
    for i, line in enumerate(lines):
        if line.strip().startswith('import '):
            last_import_idx = i
    
    # æ·»åŠ  imports
    new_imports = []
    if needs_translation:
        new_imports.append('import { useTranslation } from "react-i18next";')
    if needs_seo:
        new_imports.append('import SEOHead from "@/components/seo/SEOHead";')
    
    if new_imports:
        lines.insert(last_import_idx + 1, '\n'.join(new_imports))
    
    return '\n'.join(lines)

def add_translation_hook(content):
    """æ·»åŠ  useTranslation hook"""
    if has_translation_hook(content):
        return content
    
    # æ‰¾åˆ°å‡½æ•¸çµ„ä»¶çš„é–‹å§‹ä½ç½®
    pattern = r'(export default function \w+\(\) \{)'
    replacement = r'\1\n  const { t } = useTranslation();'
    
    return re.sub(pattern, replacement, content)

def add_seo_head(content, page_name):
    """æ·»åŠ  SEOHead çµ„ä»¶"""
    if has_seo_component(content):
        return content
    
    seo_key = PAGE_CONFIG.get(page_name, {}).get('seo', page_name.lower())
    
    # æ‰¾åˆ° return èªå¥å¾Œçš„ç¬¬ä¸€å€‹ div æˆ– fragment
    pattern = r'(return \(\s*<)(div|>)'
    seo_component = f'<SEOHead pageKey="{seo_key}" />\n      '
    replacement = rf'\1{seo_component}\2'
    
    return re.sub(pattern, replacement, content, count=1)

def is_data_block(line):
    """åˆ¤æ–·æ˜¯å¦ç‚ºè³‡æ–™å€å¡Šï¼ˆéœ€è¦è·³éç¿»è­¯ï¼‰"""
    # è·³é const è³‡æ–™é™£åˆ—å®šç¾©
    if re.match(r'\s*const\s+\w+\s*=\s*\[', line):
        return True
    # è·³éç‰©ä»¶å±¬æ€§ä¸­çš„è³‡æ–™
    if re.search(r'(name|address|phone|email|url|description):\s*["\']', line):
        return True
    return False

def should_translate_text(text, context_line=''):
    """åˆ¤æ–·æ–‡å­—æ˜¯å¦éœ€è¦ç¿»è­¯"""
    # è·³é URL
    if text.startswith('http'):
        return False
    # è·³éè·¯å¾‘
    if '/' in text and not ' ' in text:
        return False
    # è·³é className
    if 'className' in context_line:
        return False
    # è·³é Tailwind classes
    if any(x in text for x in ['px-', 'py-', 'bg-', 'text-', 'border-', 'rounded-', 'flex', 'grid']):
        return False
    # è·³éé›»è©±è™Ÿç¢¼
    if re.match(r'[\d\-\(\)\s]+$', text):
        return False
    # è·³éå–®å­—ç¬¦
    if len(text) <= 1:
        return False
    # åªç¿»è­¯åŒ…å«ä¸­æ–‡çš„æ–‡å­—
    if not re.search(r'[\u4e00-\u9fff]', text):
        return False
    
    return True

def extract_translation_key(text, page_key):
    """å¾æ–‡å­—ç”Ÿæˆç¿»è­¯ key"""
    # ç°¡åŒ–æ–‡å­—ä½œç‚º key
    key = text[:20].strip()
    # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
    key = re.sub(r'[^\w\s]', '', key)
    # è½‰æ›ç‚º camelCase
    words = key.split()
    if words:
        key = words[0].lower() + ''.join(w.capitalize() for w in words[1:])
    else:
        key = 'text'
    
    return f'{page_key}.{key}'

def process_page(page_name):
    """è™•ç†å–®å€‹é é¢"""
    page_file = PAGES_DIR / f'{page_name}.tsx'
    
    if not page_file.exists():
        print(f'âš ï¸  é é¢ä¸å­˜åœ¨: {page_name}')
        return False
    
    print(f'\nğŸ“„ è™•ç†é é¢: {page_name}')
    
    # è®€å–æª”æ¡ˆ
    with open(page_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å‚™ä»½åŸå§‹æª”æ¡ˆ
    backup_file = page_file.with_suffix('.tsx.backup')
    with open(backup_file, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f'   âœ… å‚™ä»½åŸå§‹æª”æ¡ˆ: {backup_file.name}')
    
    # æ·»åŠ  imports
    content = add_imports(content, page_name)
    print(f'   âœ… æ·»åŠ å¿…è¦çš„ imports')
    
    # æ·»åŠ  useTranslation hook
    content = add_translation_hook(content)
    print(f'   âœ… æ·»åŠ  useTranslation hook')
    
    # æ·»åŠ  SEOHead çµ„ä»¶
    content = add_seo_head(content, page_name)
    print(f'   âœ… æ·»åŠ  SEOHead çµ„ä»¶')
    
    # ä¿å­˜ä¿®æ”¹å¾Œçš„æª”æ¡ˆ
    with open(page_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f'   âœ… é é¢è™•ç†å®Œæˆ')
    
    return True

def main():
    """ä¸»å‡½æ•¸"""
    print('ğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç†æ‰€æœ‰é é¢...\n')
    print('=' * 60)
    
    success_count = 0
    failed_count = 0
    
    for page_name in TARGET_PAGES:
        try:
            if process_page(page_name):
                success_count += 1
            else:
                failed_count += 1
        except Exception as e:
            print(f'âŒ è™•ç† {page_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
            failed_count += 1
    
    print('\n' + '=' * 60)
    print(f'\nâœ… æ‰¹æ¬¡è™•ç†å®Œæˆï¼')
    print(f'ğŸ“Š æˆåŠŸ: {success_count} å€‹é é¢')
    print(f'ğŸ“Š å¤±æ•—: {failed_count} å€‹é é¢')
    print(f'\nğŸ’¡ æç¤º: åŸå§‹æª”æ¡ˆå·²å‚™ä»½ç‚º .tsx.backup')
    print(f'ğŸ’¡ å¦‚éœ€é‚„åŸï¼Œè«‹åŸ·è¡Œ: rm *.tsx && mv *.tsx.backup *.tsx')

if __name__ == '__main__':
    main()
