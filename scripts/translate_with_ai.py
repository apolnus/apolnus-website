#!/usr/bin/env python3
"""
AI è‡ªå‹•ç¿»è­¯è…³æœ¬
ä½¿ç”¨ Forge API å°‡ en.json ä¸­çš„ [EN] ä½”ä½ç¬¦ç¿»è­¯ç‚ºå°ˆæ¥­è‹±æ–‡
"""
import os
import json
import urllib.request
import time
from pathlib import Path

# è¨­å®š
LOCALE_DIR = Path("client/src/i18n/locales")
TARGET_FILE = LOCALE_DIR / "en.json"
BASE_URL = os.environ.get("BUILT_IN_FORGE_API_URL", "https://forge.manus.ai")
API_URL = f"{BASE_URL}/v1/chat/completions" if not BASE_URL.endswith('/completions') else BASE_URL
API_KEY = os.environ.get("BUILT_IN_FORGE_API_KEY") or os.environ.get("VITE_APP_ID")  # Fallback check

# å¦‚æœç’°å¢ƒè®Šæ•¸æ²’æŠ“åˆ°ï¼Œå˜—è©¦è®€å– .env
if not API_KEY:
    try:
        with open(".env", "r") as f:
            for line in f:
                if line.startswith("BUILT_IN_FORGE_API_KEY="):
                    API_KEY = line.strip().split("=", 1)[1]
                    break
    except:
        pass

if not API_KEY:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° BUILT_IN_FORGE_API_KEYï¼Œç„¡æ³•é€²è¡Œ AI ç¿»è­¯")
    exit(1)

def call_llm(text_map):
    """èª¿ç”¨ LLM API é€²è¡Œç¿»è­¯"""
    prompt = f"""You are a professional translator for a high-end home appliance brand "Apolnus".
Translate the following Traditional Chinese texts to English.

Requirements:
1. Tone: Professional, Premium, Confident.
2. Keep specific terms: "Apolnus", "Ultra S7", "One X".
3. Return ONLY a valid JSON object mapping the keys to the translated values.
4. DO NOT include any explanation, just return the JSON object.

Input JSON:
{json.dumps(text_map, ensure_ascii=False)}

Output JSON (keys must match input keys exactly):
"""
    
    payload = {
        "model": "gemini-2.0-flash-exp",
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }
    
    req = urllib.request.Request(
        API_URL,
        data=json.dumps(payload).encode('utf-8'),
        headers={
            "Content-Type": "application/json",
            "Authorization": f"Bearer {API_KEY}"
        }
    )
    
    try:
        print(f"  â†’ API URL: {API_URL}")
        print(f"  â†’ Payload size: {len(json.dumps(payload))} bytes")
        with urllib.request.urlopen(req) as response:
            result = json.loads(response.read().decode('utf-8'))
            content = result['choices'][0]['message']['content'].strip()
            
            # Try to extract JSON from markdown code blocks
            if content.startswith('```'):
                lines = content.split('\n')
                content = '\n'.join(lines[1:-1])  # Remove first and last line (```json and ```)
            
            # Try to find JSON object in the content
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            if start_idx >= 0 and end_idx > start_idx:
                content = content[start_idx:end_idx]
            
            return json.loads(content)
    except urllib.error.HTTPError as e:
        print(f"âš ï¸ HTTP Error {e.code}: {e.reason}")
        print(f"  â†’ Response: {e.read().decode('utf-8') if e.fp else 'No response body'}")
        return {}
    except Exception as e:
        print(f"âš ï¸ API èª¿ç”¨å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return {}

def process_translations():
    """è™•ç†ç¿»è­¯"""
    print("ğŸš€ é–‹å§‹ AI è‡ªå‹•ç¿»è­¯ (zh-TW -> en)...")
    
    with open(TARGET_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # æ‰¾å‡ºæ‰€æœ‰éœ€è¦ç¿»è­¯çš„é …ç›® (éè¿´æœå°‹)
    tasks = {}
    
    def find_tasks(obj, path=""):
        for k, v in obj.items():
            curr_path = f"{path}.{k}" if path else k
            if isinstance(v, dict):
                find_tasks(v, curr_path)
            elif isinstance(v, str) and v.startswith("[EN] "):
                # æå–åŸå§‹ä¸­æ–‡: "[EN] ç”¢å“ä»‹ç´¹" -> "ç”¢å“ä»‹ç´¹"
                tasks[curr_path] = v.replace("[EN] ", "")
    
    find_tasks(data)
    total = len(tasks)
    print(f"ğŸ“‹ ç™¼ç¾ {total} å€‹å¾…ç¿»è­¯é …ç›®")
    
    if total == 0:
        print("âœ… æ²’æœ‰éœ€è¦ç¿»è­¯çš„é …ç›®")
        return
    
    # æ‰¹æ¬¡è™•ç† (æ¯æ‰¹ 5 å€‹ï¼Œé¿å… JSON è§£æéŒ¯èª¤)
    batch_size = 5
    task_items = list(tasks.items())
    
    for i in range(0, total, batch_size):
        batch = dict(task_items[i:i+batch_size])
        print(f"ğŸ”„ è™•ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(total + batch_size - 1)//batch_size} ({len(batch)} å€‹é …ç›®)...")
        
        translations = call_llm(batch)
        
        # æ›´æ–°åŸå§‹è³‡æ–™
        for key_path, translated_text in translations.items():
            # æ›´æ–° nested dict
            keys = key_path.split('.')
            target = data
            for k in keys[:-1]:
                target = target[k]
            target[keys[-1]] = translated_text
            print(f"  âœ“ {key_path}")
        
        # ç¨å¾®å»¶é²é¿å… Rate Limit
        time.sleep(1)
    
    # å¯«å›æª”æ¡ˆ
    with open(TARGET_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ç¿»è­¯å®Œæˆï¼{total} å€‹é …ç›®å·²æ›´æ–°åˆ° en.json")

if __name__ == "__main__":
    process_translations()
