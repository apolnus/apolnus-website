#!/usr/bin/env python3
"""
é€šç”¨è…³æœ¬ï¼šæ‰¹æ¬¡è™•ç†æ‰€æœ‰å‰©é¤˜é é¢
ä½¿ç”¨åºåˆ—åŒ– Keyï¼ŒåŒæ™‚æ›´æ–°ä»£ç¢¼å’Œ JSON
"""

import re
import json
from pathlib import Path

# å‰©é¤˜é é¢åˆ—è¡¨
REMAINING_PAGES = [
    'About',
    'FAQ',
    'NotFound',
    'Privacy',
    'Terms',
    'Profile',
    'WarrantyRegistration',
    'SupportTicket',
    'Tickets',
    'Support',
    'PartnerProgram',
    'Careers',
]

PAGES_DIR = Path('/home/ubuntu/apolnus/client/src/pages')
TRANSLATIONS_DIR = Path('/home/ubuntu/apolnus/client/src/i18n/locales')

# è¼‰å…¥ç¾æœ‰ç¿»è­¯
with open(TRANSLATIONS_DIR / 'zh-TW.json', 'r', encoding='utf-8') as f:
    zh_tw = json.load(f)

with open(TRANSLATIONS_DIR / 'en.json', 'r', encoding='utf-8') as f:
    en = json.load(f)

def contains_chinese(text):
    """æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡"""
    return bool(re.search(r'[\u4e00-\u9fff]', text))

def extract_chinese_texts(content):
    """æå–æ‰€æœ‰ä¸­æ–‡æ–‡å­—"""
    texts = []
    
    # æå– JSX æ¨™ç±¤å…§çš„æ–‡å­—
    pattern = r'>([^<{]+)<'
    matches = re.findall(pattern, content)
    for match in matches:
        text = match.strip()
        if contains_chinese(text) and len(text) > 1:
            texts.append(text)
    
    # æå–å±¬æ€§ä¸­çš„æ–‡å­—
    attr_pattern = r'(placeholder|alt|title|aria-label)\s*=\s*["\']([^"\']+)["\']'
    attr_matches = re.findall(attr_pattern, content)
    for _, text in attr_matches:
        if contains_chinese(text):
            texts.append(text)
    
    return texts

def process_page(page_name):
    """è™•ç†å–®å€‹é é¢"""
    page_file = PAGES_DIR / f'{page_name}.tsx'
    
    if not page_file.exists():
        print(f'âš ï¸  é é¢ä¸å­˜åœ¨: {page_name}')
        return False
    
    print(f'\nğŸ“„ è™•ç†é é¢: {page_name}')
    
    # è®€å–æª”æ¡ˆ
    with open(page_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–ä¸­æ–‡æ–‡å­—
    chinese_texts = extract_chinese_texts(content)
    
    if not chinese_texts:
        print(f'   â„¹ï¸  æ²’æœ‰æ‰¾åˆ°ä¸­æ–‡æ–‡å­—')
        return True
    
    # å»é‡ä¸¦ä¿æŒé †åº
    unique_texts = []
    seen = set()
    for text in chinese_texts:
        if text not in seen:
            unique_texts.append(text)
            seen.add(text)
    
    print(f'   âœ… æ‰¾åˆ° {len(unique_texts)} å€‹ä¸­æ–‡æ–‡å­—')
    
    # ç”Ÿæˆç¿»è­¯ key å’Œå…§å®¹
    page_key = page_name[0].lower() + page_name[1:]  # camelCase
    translations_zh = {}
    translations_en = {}
    
    for i, text in enumerate(unique_texts, 1):
        key = f'p_{i:02d}'
        translations_zh[key] = text
        translations_en[key] = f'[EN] {text}'  # æš«æ™‚ä½¿ç”¨å ä½ç¬¦
        
        # æ›¿æ›æ–‡å­—ç‚ºç¿»è­¯ key
        # åªæ›¿æ›å®Œæ•´åŒ¹é…çš„æ–‡å­—
        escaped_text = re.escape(text)
        # æ›¿æ› JSX æ¨™ç±¤å…§çš„æ–‡å­—
        content = re.sub(
            rf'>({escaped_text})<',
            rf'>{{t(\'{page_key}.{key}\')}}<',
            content
        )
        # æ›¿æ›å±¬æ€§ä¸­çš„æ–‡å­—
        content = re.sub(
            rf'(placeholder|alt|title|aria-label)\s*=\s*["\']({escaped_text})["\']',
            rf'\1={{t(\'{page_key}.{key}\')}}',
            content
        )
    
    # ä¿å­˜ä¿®æ”¹å¾Œçš„æª”æ¡ˆ
    with open(page_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    # æ›´æ–°ç¿»è­¯ JSON
    zh_tw[page_key] = translations_zh
    en[page_key] = translations_en
    
    print(f'   âœ… é é¢è™•ç†å®Œæˆï¼Œç”Ÿæˆ {len(translations_zh)} å€‹ç¿»è­¯ key')
    
    return True

def main():
    """ä¸»å‡½æ•¸"""
    print('ğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç†æ‰€æœ‰å‰©é¤˜é é¢...\n')
    print('=' * 60)
    
    success_count = 0
    failed_count = 0
    
    for page_name in REMAINING_PAGES:
        try:
            if process_page(page_name):
                success_count += 1
            else:
                failed_count += 1
        except Exception as e:
            print(f'âŒ è™•ç† {page_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
            import traceback
            traceback.print_exc()
            failed_count += 1
    
    # ä¿å­˜æ›´æ–°å¾Œçš„ç¿»è­¯
    with open(TRANSLATIONS_DIR / 'zh-TW.json', 'w', encoding='utf-8') as f:
        json.dump(zh_tw, f, ensure_ascii=False, indent=2)
    
    with open(TRANSLATIONS_DIR / 'en.json', 'w', encoding='utf-8') as f:
        json.dump(en, f, ensure_ascii=False, indent=2)
    
    print('\n' + '=' * 60)
    print(f'\nâœ… æ‰¹æ¬¡è™•ç†å®Œæˆï¼')
    print(f'ğŸ“Š æˆåŠŸ: {success_count} å€‹é é¢')
    print(f'ğŸ“Š å¤±æ•—: {failed_count} å€‹é é¢')
    print(f'\nğŸ’¾ ç¿»è­¯æª”æ¡ˆå·²æ›´æ–°: zh-TW.json, en.json')

if __name__ == '__main__':
    main()
